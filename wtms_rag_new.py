__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import os
import streamlit as st
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any
import re

from langchain_chroma import Chroma
from langchain_community.document_loaders import UnstructuredMarkdownLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.schema import Document

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    st.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"

# ìƒìˆ˜ ì„¤ì •
CHUNK_SIZE = int(os.getenv('CHUNK_SIZE', '1000'))
CHUNK_OVERLAP = int(os.getenv('CHUNK_OVERLAP', '200'))
MAX_CHAT_HISTORY = int(os.getenv('MAX_CHAT_HISTORY', '50'))
SIMILARITY_THRESHOLD = float(os.getenv('SIMILARITY_THRESHOLD', '0.7'))

class AdvancedRAGSystem:
    def __init__(self):
        self.vectorstore = None
        self.retriever = None
        self.rag_chain = None
        self.chat_history = []
        self.feedback_data = []
        self.query_analytics = {}
        
    def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            file_path = "./all_pages.md"
            if not os.path.exists(file_path):
                st.error(f"âŒ {file_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return False
            
            # ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            docs = self.load_and_split_documents(file_path)
            self.vectorstore = self.create_or_load_vectorstore(docs)
            self.retriever = self.create_advanced_retriever()
            self.rag_chain = self.create_rag_chain()
            
            # ë¶„ì„ ë°ì´í„° ë¡œë“œ
            self.load_analytics_data()
            
            return True
        except Exception as e:
            st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    @st.cache_data
    def load_and_split_documents(_self, file_path: str) -> List[Document]:
        """ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• """
        loader = UnstructuredMarkdownLoader(file_path)
        documents = loader.load()
        
        # í–¥ìƒëœ í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=CHUNK_SIZE,
            chunk_overlap=CHUNK_OVERLAP,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
            length_function=len,
        )
        
        split_docs = text_splitter.split_documents(documents)
        
        # ë©”íƒ€ë°ì´í„° í–¥ìƒ
        for i, doc in enumerate(split_docs):
            doc.metadata.update({
                'chunk_id': i,
                'source_file': file_path,
                'processed_at': datetime.now().isoformat(),
                'chunk_length': len(doc.page_content)
            })
        
        return split_docs
    
    @st.cache_resource
    def create_or_load_vectorstore(_self, docs: List[Document]):
        """ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë˜ëŠ” ë¡œë“œ"""
        persist_directory = "/tmp/chroma_db"
        
        embeddings = OpenAIEmbeddings(
            model='text-embedding-3-small',
            dimensions=1536
        )
        
        if os.path.exists(persist_directory):
            try:
                vectorstore = Chroma(
                    persist_directory=persist_directory,
                    embedding_function=embeddings
                )
                # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                if vectorstore._collection.count() > 0:
                    return vectorstore
            except Exception as e:
                st.warning(f"ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ìƒˆë¡œìš´ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = Chroma.from_documents(
            documents=docs,
            embedding=embeddings,
            persist_directory=persist_directory,
            collection_metadata={"hnsw:space": "cosine"}
        )
        return vectorstore
    
    def create_advanced_retriever(self):
        """ê³ ê¸‰ ê²€ìƒ‰ê¸° ìƒì„±"""
        retriever = self.vectorstore.as_retriever(
            search_type="mmr",  # Maximum Marginal Relevance
            search_kwargs={
                "k": 5,
                "fetch_k": 10,
                "lambda_mult": 0.7
            }
        )
        return retriever
    
    def create_rag_chain(self):
        """í–¥ìƒëœ RAG ì²´ì¸ ìƒì„±"""
        qa_system_prompt = """
        ë‹¹ì‹ ì€ í˜¸ë‚¨ê¶Œ ìˆ˜ì§ˆTMS ê´€ì œì„¼í„°ì˜ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        
        ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ ë‹µë³€í•´ì£¼ì„¸ìš”:
        1. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
        2. ë‹µë³€ì„ ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš°, ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”.
        3. í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        4. ê´€ë ¨ ë²•ë ¹ì´ë‚˜ ê·œì •ì´ ìˆë‹¤ë©´ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
        5. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
        6. ë‹µë³€ì˜ ì‹ ë¢°ë„ê°€ ë‚®ë‹¤ë©´ ì¶”ê°€ í™•ì¸ì„ ê¶Œì¥í•˜ì„¸ìš”.
        
        ì»¨í…ìŠ¤íŠ¸: {context}
        
        ì±„íŒ… ê¸°ë¡: {chat_history}
        """
        
        qa_prompt = ChatPromptTemplate.from_messages([
            ("system", qa_system_prompt),
            ("human", "{input}"),
        ])
        
        llm = ChatOpenAI(
            model=os.getenv('OPENAI_MODEL', 'gpt-4o-mini'),
            temperature=0.1,
            max_tokens=1000
        )
        
        def enhanced_format_docs(docs):
            """í–¥ìƒëœ ë¬¸ì„œ í¬ë§·íŒ…"""
            if not docs:
                return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            formatted = []
            for i, doc in enumerate(docs, 1):
                content = doc.page_content.strip()
                source = doc.metadata.get('source_file', 'ì•Œ ìˆ˜ ì—†ìŒ')
                formatted.append(f"[ì°¸ê³ ìë£Œ {i}]\n{content}\n")
            
            return "\n".join(formatted)
        
        def add_chat_history(inputs):
            """ì±„íŒ… ê¸°ë¡ ì¶”ê°€"""
            inputs["chat_history"] = self.format_chat_history()
            return inputs
        
        rag_chain = (
            {"context": self.retriever | enhanced_format_docs, "input": RunnablePassthrough()}
            | RunnablePassthrough.assign(chat_history=lambda x: self.format_chat_history())
            | qa_prompt
            | llm
            | StrOutputParser()
        )
        
        return rag_chain
    
    def format_chat_history(self, limit: int = 3) -> str:
        """ìµœê·¼ ì±„íŒ… ê¸°ë¡ í¬ë§·íŒ…"""
        if not self.chat_history:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        recent_history = self.chat_history[-limit:]
        formatted = []
        
        for exchange in recent_history:
            if 'user' in exchange and 'assistant' in exchange:
                formatted.append(f"ì‚¬ìš©ì: {exchange['user']}")
                formatted.append(f"ì–´ì‹œìŠ¤í„´íŠ¸: {exchange['assistant'][:100]}...")
        
        return "\n".join(formatted)
    
    def query_with_analytics(self, query: str) -> Dict[str, Any]:
        """ë¶„ì„ ê¸°ëŠ¥ì´ í¬í•¨ëœ ì¿¼ë¦¬ ì²˜ë¦¬"""
        start_time = time.time()
        
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬
        processed_query = self.preprocess_query(query)
        
        # ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
        similar_queries = self.find_similar_queries(query)
        
        # RAG ì‹¤í–‰
        try:
            response = self.rag_chain.invoke(processed_query)
            
            # ì‘ë‹µ í›„ì²˜ë¦¬
            enhanced_response = self.postprocess_response(response, query)
            
            # ë¶„ì„ ë°ì´í„° ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self.update_analytics(query, processing_time, True)
            
            return {
                'response': enhanced_response,
                'similar_queries': similar_queries,
                'processing_time': processing_time,
                'success': True
            }
            
        except Exception as e:
            self.update_analytics(query, time.time() - start_time, False)
            return {
                'response': f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'similar_queries': [],
                'processing_time': time.time() - start_time,
                'success': False
            }
    
    def preprocess_query(self, query: str) -> str:
        """ì¿¼ë¦¬ ì „ì²˜ë¦¬"""
        # ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        query = re.sub(r'[^\w\sê°€-í£]', ' ', query)
        
        # í‚¤ì›Œë“œ í™•ì¥
        keyword_expansions = {
            'TMS': 'ì›ê²©ê°ì‹œì²´ê³„ TMS í…”ë ˆë©”íŠ¸ë¦¬',
            'ìˆ˜ì§ˆ': 'ìˆ˜ì§ˆ ì˜¤ì—¼ ì¸¡ì • ëª¨ë‹ˆí„°ë§',
            'ê´€ì œ': 'ê´€ì œ ëª¨ë‹ˆí„°ë§ ê°ì‹œ ì œì–´',
            'COD': 'COD í™”í•™ì ì‚°ì†Œìš”êµ¬ëŸ‰',
            'BOD': 'BOD ìƒí™”í•™ì ì‚°ì†Œìš”êµ¬ëŸ‰'
        }
        
        for keyword, expansion in keyword_expansions.items():
            if keyword in query:
                query = query.replace(keyword, expansion)
        
        return query.strip()
    
    def postprocess_response(self, response: str, original_query: str) -> str:
        """ì‘ë‹µ í›„ì²˜ë¦¬"""
        # ì‹ ë¢°ë„ í‰ê°€
        confidence_keywords = ['í™•ì‹¤', 'ëª…í™•', 'ì •í™•', 'ê·œì •', 'ë²•ë ¹']
        uncertainty_keywords = ['ì•„ë§ˆ', 'ì¶”ì •', 'ê°€ëŠ¥ì„±', 'ì•Œ ìˆ˜ ì—†']
        
        confidence_score = sum(1 for keyword in confidence_keywords if keyword in response)
        uncertainty_score = sum(1 for keyword in uncertainty_keywords if keyword in response)
        
        # ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš° ê²½ê³  ì¶”ê°€
        if uncertainty_score > confidence_score:
            response += "\n\nâš ï¸ **ì°¸ê³ **: ì´ ë‹µë³€ì˜ ì •í™•ì„±ì„ ìœ„í•´ ê´€ë ¨ ë²•ë ¹ì´ë‚˜ ê³µì‹ ë¬¸ì„œë¥¼ í™•ì¸í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        # ê´€ë ¨ ë§í¬ë‚˜ ì¶”ê°€ ì •ë³´ ì œì•ˆ
        if any(keyword in original_query.lower() for keyword in ['ë²•ë ¹', 'ê·œì •', 'ê¸°ì¤€']):
            response += "\n\nğŸ“‹ **ì¶”ê°€ ì •ë³´**: ì •í™•í•œ ë²•ì  ê¸°ì¤€ì€ í™˜ê²½ë¶€ í™ˆí˜ì´ì§€ë‚˜ ê´€ë ¨ ë²•ë ¹ì„ ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        
        return response
    
    def find_similar_queries(self, query: str, limit: int = 3) -> List[str]:
        """ìœ ì‚¬í•œ ì´ì „ ì§ˆë¬¸ ì°¾ê¸°"""
        if not hasattr(self, 'query_analytics') or not self.query_analytics:
            return []
        
        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ì„ë² ë”© ê¸°ë°˜ìœ¼ë¡œ ê°œì„  ê°€ëŠ¥)
        query_words = set(query.lower().split())
        similar = []
        
        for past_query, data in self.query_analytics.items():
            past_words = set(past_query.lower().split())
            similarity = len(query_words & past_words) / len(query_words | past_words)
            
            if similarity > SIMILARITY_THRESHOLD:
                similar.append((past_query, similarity))
        
        similar.sort(key=lambda x: x[1], reverse=True)
        return [q for q, _ in similar[:limit]]
    
    def update_analytics(self, query: str, processing_time: float, success: bool):
        """ë¶„ì„ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        if query not in self.query_analytics:
            self.query_analytics[query] = {
                'count': 0,
                'avg_time': 0,
                'success_rate': 0,
                'last_asked': None
            }
        
        data = self.query_analytics[query]
        data['count'] += 1
        data['avg_time'] = (data['avg_time'] * (data['count'] - 1) + processing_time) / data['count']
        data['success_rate'] = (data['success_rate'] * (data['count'] - 1) + (1 if success else 0)) / data['count']
        data['last_asked'] = datetime.now().isoformat()
    
    def add_to_chat_history(self, user_msg: str, assistant_msg: str):
        """ì±„íŒ… ê¸°ë¡ ì¶”ê°€"""
        self.chat_history.append({
            'user': user_msg,
            'assistant': assistant_msg,
            'timestamp': datetime.now().isoformat()
        })
        
        # ê¸°ë¡ ê¸¸ì´ ì œí•œ
        if len(self.chat_history) > MAX_CHAT_HISTORY:
            self.chat_history = self.chat_history[-MAX_CHAT_HISTORY:]
    
    def save_feedback(self, query: str, response: str, rating: int, comment: str = ""):
        """í”¼ë“œë°± ì €ì¥"""
        feedback = {
            'query': query,
            'response': response,
            'rating': rating,
            'comment': comment,
            'timestamp': datetime.now().isoformat()
        }
        self.feedback_data.append(feedback)
        
        # ì„ì‹œ ì €ì¥ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ íŒŒì¼ì— ì €ì¥)
        try:
            with open('/tmp/feedback.json', 'w', encoding='utf-8') as f:
                json.dump(self.feedback_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.warning(f"í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_analytics_data(self):
        """ë¶„ì„ ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists('/tmp/analytics.json'):
                with open('/tmp/analytics.json', 'r', encoding='utf-8') as f:
                    self.query_analytics = json.load(f)
        except Exception:
            self.query_analytics = {}
    
    def save_analytics_data(self):
        """ë¶„ì„ ë°ì´í„° ì €ì¥"""
        try:
            with open('/tmp/analytics.json', 'w', encoding='utf-8') as f:
                json.dump(self.query_analytics, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.warning(f"ë¶„ì„ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

# Streamlit UI
def main():
    st.set_page_config(
        page_title="í˜¸ë‚¨ê¶Œ WTMS Q&A ì±—ë´‡",
        page_icon="ğŸ’¬",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title("ğŸ”§ ì‹œìŠ¤í…œ ì„¤ì •")
        
        # ëª¨ë¸ ì„¤ì •
        model_options = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
        selected_model = st.selectbox("ëª¨ë¸ ì„ íƒ", model_options)
        os.environ['OPENAI_MODEL'] = selected_model
        
        # ê²€ìƒ‰ ì„¤ì •
        st.subheader("ê²€ìƒ‰ ì„¤ì •")
        search_type = st.selectbox("ê²€ìƒ‰ ë°©ì‹", ["mmr", "similarity"])
        num_results = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 3, 10, 5)
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        if 'rag_system' in st.session_state:
            if hasattr(st.session_state.rag_system, 'query_analytics'):
                total_queries = len(st.session_state.rag_system.query_analytics)
                st.metric("ì´ ì§ˆë¬¸ ìˆ˜", total_queries)
                
                if total_queries > 0:
                    avg_success_rate = sum(data['success_rate'] for data in st.session_state.rag_system.query_analytics.values()) / total_queries
                    st.metric("í‰ê·  ì„±ê³µë¥ ", f"{avg_success_rate:.1%}")
        
        # ë°ì´í„° ê´€ë¦¬
        st.subheader("ğŸ—ƒï¸ ë°ì´í„° ê´€ë¦¬")
        if st.button("ë¶„ì„ ë°ì´í„° ì €ì¥"):
            if 'rag_system' in st.session_state:
                st.session_state.rag_system.save_analytics_data()
                st.success("ì €ì¥ ì™„ë£Œ!")
        
        if st.button("ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
            if 'messages' in st.session_state:
                st.session_state.messages = [
                    {"role": "assistant", "content": "ìˆ˜ì§ˆê´€ì œì‹œìŠ¤í…œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š"}
                ]
                st.success("ì±„íŒ… ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ë©”ì¸ í™”ë©´
    st.title("í˜¸ë‚¨ê¶Œ WTMS Q&A ì±—ë´‡ ğŸ’¬")
    st.markdown("""
    <div style='background-color: #f0f2f6; padding: 15px; border-radius: 10px; margin-bottom: 20px;'>
    ğŸŒŠ <strong>ìˆ˜ì§ˆTMS ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸</strong><br>
    ë³¸ ì„œë¹„ìŠ¤ëŠ” í•œêµ­í™˜ê²½ê³µë‹¨ í˜¸ë‚¨ê¶Œ ìˆ˜ì§ˆTMS ê´€ì œì„¼í„°ì— ì˜í•´ ìš´ì˜ë˜ë©°, 
    ì±—ë´‡ì˜ ë‹µë³€ì—ëŠ” ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì¤‘ìš”í•œ ì‚¬í•­ì€ ë°˜ë“œì‹œ ë²•ë ¹ ë“± ì¶œì²˜ë¥¼ í™•ì¸í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤. ğŸ“–
    </div>
    """, unsafe_allow_html=True)
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if 'rag_system' not in st.session_state:
        with st.spinner("ğŸ”„ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            st.session_state.rag_system = AdvancedRAGSystem()
            if st.session_state.rag_system.initialize():
                st.success("âœ… ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                st.error("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.stop()
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ìˆ˜ì§ˆê´€ì œì‹œìŠ¤í…œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š"}
        ]
    
    if "feedback_mode" not in st.session_state:
        st.session_state.feedback_mode = False
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    chat_container = st.container()
    
    with chat_container:
        # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
        for i, msg in enumerate(st.session_state.messages):
            with st.chat_message(msg['role']):
                st.write(msg['content'])
                
                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ì— í”¼ë“œë°± ë²„íŠ¼ ì¶”ê°€
                if msg['role'] == 'assistant' and i > 0:  # ì²« ë²ˆì§¸ í™˜ì˜ ë©”ì‹œì§€ ì œì™¸
                    col1, col2, col3, col4 = st.columns([1, 1, 1, 6])
                    
                    with col1:
                        if st.button("ğŸ‘", key=f"good_{i}"):
                            st.session_state.rag_system.save_feedback(
                                st.session_state.messages[i-1]['content'],
                                msg['content'],
                                5,
                                "ì¢‹ìŒ"
                            )
                            st.success("í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤!")
                    
                    with col2:
                        if st.button("ğŸ‘", key=f"bad_{i}"):
                            st.session_state.rag_system.save_feedback(
                                st.session_state.messages[i-1]['content'],
                                msg['content'],
                                1,
                                "ë‚˜ì¨"
                            )
                            st.warning("í”¼ë“œë°±ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                    with col3:
                        if st.button("ğŸ”„", key=f"retry_{i}"):
                            # ì¬ìƒì„± ë¡œì§
                            with st.spinner("ë‹µë³€ì„ ë‹¤ì‹œ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                result = st.session_state.rag_system.query_with_analytics(
                                    st.session_state.messages[i-1]['content']
                                )
                                st.session_state.messages[i] = {
                                    "role": "assistant", 
                                    "content": result['response']
                                }
                                st.rerun()
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” ğŸ˜Š"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("human"):
            st.write(prompt)
        st.session_state.messages.append({"role": "human", "content": prompt})
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                result = st.session_state.rag_system.query_with_analytics(prompt)
                
                # ì‘ë‹µ í‘œì‹œ
                st.write(result['response'])
                
                # ì„±ëŠ¥ ì •ë³´ í‘œì‹œ
                col1, col2 = st.columns(2)
                with col1:
                    st.caption(f"â±ï¸ ì²˜ë¦¬ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
                with col2:
                    if result['success']:
                        st.caption("âœ… ì„±ê³µ")
                    else:
                        st.caption("âŒ ì‹¤íŒ¨")
                
                # ìœ ì‚¬ ì§ˆë¬¸ í‘œì‹œ
                if result['similar_queries']:
                    with st.expander("ğŸ” ê´€ë ¨ ì§ˆë¬¸ë“¤"):
                        for similar_q in result['similar_queries']:
                            st.write(f"â€¢ {similar_q}")
                
                # ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": result['response']
                })
                
                # ì±„íŒ… ê¸°ë¡ ì—…ë°ì´íŠ¸
                st.session_state.rag_system.add_to_chat_history(prompt, result['response'])

if __name__ == "__main__":
    main()
